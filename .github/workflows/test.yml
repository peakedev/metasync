name: Local Tests 

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      checks: write
      pull-requests: write
    
    services:
      mongo:
        image: mongo:7.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.runCommand({ ping: 1 })'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      
      - name: Install MongoDB tools
        run: |
          wget -qO - https://www.mongodb.org/static/pgp/server-7.0.asc | sudo apt-key add -
          echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
          sudo apt-get update
          sudo apt-get install -y mongodb-mongosh mongodb-database-tools
      
      - name: Wait for MongoDB to be ready
        run: |
          echo "Waiting for MongoDB to be ready..."
          for i in {1..30}; do
            if mongosh --host localhost --port 27017 --eval "db.runCommand({ ping: 1 })" > /dev/null 2>&1; then
              echo "MongoDB is ready!"
              break
            fi
            echo "Waiting... ($i/30)"
            sleep 2
          done
      
      - name: Initialize MongoDB with test data
        run: |
          # Import all test data files
          for file in tests/data/*.json; do
            collection=$(basename "$file" .json)
            echo "Importing $collection from $file..."
            
            # Check if file has actual data (not just empty array)
            if grep -q '"' "$file"; then
              mongoimport --host localhost --port 27017 --db metasync-test --collection "$collection" --file "$file" --jsonArray
            else
              echo "  Skipping $collection (empty array)"
            fi
          done
          
          # Create index on priority field in jobs collection
          echo "Creating index on jobs.priority..."
          mongosh --host localhost --port 27017 metasync-test --eval 'db.jobs.createIndex({ priority: -1 })'
          
          # Verify data was loaded
          echo "Verifying data load..."
          mongosh --host localhost --port 27017 metasync-test --eval 'db.getCollectionNames().forEach(function(col) { print(col + ": " + db[col].countDocuments()); })'
      
      - name: Build Docker image
        run: |
          docker build -t metasync:test .
      
      - name: Start metasync container
        run: |
          # Start container using env file (with absolute path for reliability)
          docker run -d \
            --name metasync \
            --network host \
            --env-file "${GITHUB_WORKSPACE}/tests/pipeline-run.env" \
            metasync:test
      
      - name: Wait for metasync to be healthy
        run: |
          echo "Waiting for metasync to be healthy..."
          for i in {1..60}; do
            if curl -f http://localhost:8001/health > /dev/null 2>&1; then
              echo "Metasync is healthy!"
              curl http://localhost:8001/health
              break
            fi
            echo "Waiting... ($i/60)"
            sleep 2
          done
          
          # Final check
          if ! curl -f http://localhost:8001/health > /dev/null 2>&1; then
            echo "Metasync failed to become healthy"
            echo "Container logs:"
            docker logs metasync
            exit 1
          fi
      
      - name: Set up Node.js for Bruno
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Bruno CLI
        run: |
          npm install -g @usebruno/cli
      
      - name: Run Bruno tests
        run: |
          echo "Running Bruno test collection..."
          
          # Create results directory
          mkdir -p test-results
          
          # Run all Bruno tests as a single collection
          cd tests/bruno
          
          echo "Running full test suite..."
          set +e  # Don't exit on test failures
          bru run --env local \
            --output ../../test-results/test-results.json \
            --junit ../../test-results/results.xml \
            --html ../../test-results/report.html 2>&1 | tee /tmp/bruno-output.log
          TEST_EXIT_CODE=$?
          set -e
          
          # Return to project root
          cd - > /dev/null
          
          # Check if XML was generated
          echo ""
          echo "======== CHECKING JUNIT XML ========"
          if [ -f test-results/results.xml ]; then
            echo "‚úÖ JUnit XML file exists"
            echo "File size: $(wc -c < test-results/results.xml) bytes"
            echo "First 30 lines:"
            head -n 30 test-results/results.xml
          else
            echo "‚ùå JUnit XML file NOT found at test-results/results.xml"
            echo "Files in test-results:"
            ls -la test-results/ || echo "test-results directory doesn't exist"
          fi
          echo "======== END JUNIT XML CHECK ========"
          echo ""
          
          echo ""
          echo "======== RAW BRUNO OUTPUT (first 50 lines) ========"
          head -n 50 /tmp/bruno-output.log
          echo "======== END RAW OUTPUT ========"
          echo ""
          
          # Parse the Bruno output to create detailed test results by folder
          echo "Parsing test results..."
          
          # Initialize files
          > /tmp/test-summary.txt
          > /tmp/test-detail.txt
          
          # Dictionary to track test folders and their results
          declare -A folder_tests
          declare -A folder_passed
          declare -A folder_failed
          
          # Bruno CLI output format is typically:
          # Running Request: folder/test-name.bru
          # ... test output ...
          # ‚úî Passed or ‚úñ Failed
          
          current_folder=""
          current_test=""
          test_status=""
          
          # Parse the output line by line
          while IFS= read -r line; do
            # Look for "Running Request:" or similar patterns
            if [[ "$line" =~ Running.*:.*([a-z-]+)/([0-9]+-.*\.bru) ]] || [[ "$line" =~ ^([a-z-]+)/([0-9]+-.*\.bru) ]]; then
              # Save previous test if exists
              if [ -n "$current_test" ] && [ -n "$current_folder" ]; then
                if [ -z "${folder_tests[$current_folder]}" ]; then
                  folder_tests[$current_folder]=""
                  folder_passed[$current_folder]=0
                  folder_failed[$current_folder]=0
                fi
                
                if [ "$test_status" = "failed" ]; then
                  folder_tests[$current_folder]+="‚ùå ${current_test}"$'\n'
                  folder_failed[$current_folder]=$((${folder_failed[$current_folder]} + 1))
                else
                  folder_tests[$current_folder]+="‚úÖ ${current_test}"$'\n'
                  folder_passed[$current_folder]=$((${folder_passed[$current_folder]} + 1))
                fi
              fi
              
              # Extract new test info
              folder="${BASH_REMATCH[1]}"
              test_file="${BASH_REMATCH[2]}"
              current_test="${test_file%.bru}"
              current_folder="$folder"
              test_status="passed"  # Default to passed
              
            # Look for failure indicators
            elif echo "$line" | grep -qE "‚úñ|AssertionError|Error:|failed|FAIL"; then
              test_status="failed"
            fi
          done < /tmp/bruno-output.log
          
          # Save last test
          if [ -n "$current_test" ] && [ -n "$current_folder" ]; then
            if [ -z "${folder_tests[$current_folder]}" ]; then
              folder_tests[$current_folder]=""
              folder_passed[$current_folder]=0
              folder_failed[$current_folder]=0
            fi
            
            if [ "$test_status" = "failed" ]; then
              folder_tests[$current_folder]+="‚ùå ${current_test}"$'\n'
              folder_failed[$current_folder]=$((${folder_failed[$current_folder]} + 1))
            else
              folder_tests[$current_folder]+="‚úÖ ${current_test}"$'\n'
              folder_passed[$current_folder]=$((${folder_passed[$current_folder]} + 1))
            fi
          fi
          
          # If parsing didn't work, try parsing from file structure
          if [ ${#folder_tests[@]} -eq 0 ]; then
            echo "‚ö†Ô∏è  Primary parsing found no tests, using file-based fallback..."
            
            # Get all test folders
            for test_folder in tests/bruno/*/; do
              test_folder=${test_folder%/}
              folder_name=$(basename "$test_folder")
              
              # Skip environments folder
              if [ "$folder_name" = "environments" ]; then
                continue
              fi
              
              folder_tests[$folder_name]=""
              folder_passed[$folder_name]=0
              folder_failed[$folder_name]=0
              
              # List all .bru files in this folder
              for bru_file in "$test_folder"/*.bru; do
                if [ -f "$bru_file" ]; then
                  test_name=$(basename "$bru_file" .bru)
                  
                  # Default to passed if we can't determine
                  folder_tests[$folder_name]+="‚úÖ ${test_name}"$'\n'
                  folder_passed[$folder_name]=$((${folder_passed[$folder_name]} + 1))
                fi
              done
            done
          fi
          
          # Generate summary and detail files
          total_all_tests=0
          total_all_passed=0
          total_all_failed=0
          
          for folder in "${!folder_tests[@]}"; do
            total_tests=$((${folder_passed[$folder]} + ${folder_failed[$folder]}))
            total_all_tests=$((total_all_tests + total_tests))
            total_all_passed=$((total_all_passed + ${folder_passed[$folder]}))
            total_all_failed=$((total_all_failed + ${folder_failed[$folder]}))
            
            if [ ${folder_failed[$folder]} -eq 0 ] && [ $total_tests -gt 0 ]; then
              echo "‚úÖ ${folder} (${folder_passed[$folder]}/${total_tests})" >> /tmp/test-summary.txt
              echo "FOLDER:${folder}:PASSED" >> /tmp/test-detail.txt
            else
              echo "‚ùå ${folder} (${folder_passed[$folder]}/${total_tests})" >> /tmp/test-summary.txt
              echo "FOLDER:${folder}:FAILED" >> /tmp/test-detail.txt
            fi
            
            # Add individual test results
            echo "${folder_tests[$folder]}" >> /tmp/test-detail.txt
            echo "---" >> /tmp/test-detail.txt
          done
          
          # Generate JUnit XML if Bruno didn't create one
          if [ ! -f test-results/results.xml ] || [ ! -s test-results/results.xml ]; then
            echo "Generating JUnit XML manually..."
            
            cat > test-results/results.xml << XML_HEADER
<?xml version="1.0" encoding="UTF-8"?>
<testsuites tests="${total_all_tests}" failures="${total_all_failed}" errors="0" time="0">
XML_HEADER
            
            # Add test suites for each folder
            for folder in "${!folder_tests[@]}"; do
              total_tests=$((${folder_passed[$folder]} + ${folder_failed[$folder]}))
              
              cat >> test-results/results.xml << XML_SUITE
  <testsuite name="${folder}" tests="${total_tests}" failures="${folder_failed[$folder]}" errors="0" time="0">
XML_SUITE
              
              # Parse individual tests and add them
              while IFS= read -r test_line; do
                if [ -n "$test_line" ]; then
                  if [[ "$test_line" =~ ^‚úÖ[[:space:]](.+)$ ]]; then
                    test_name="${BASH_REMATCH[1]}"
                    echo "    <testcase name=\"${test_name}\" classname=\"${folder}\" time=\"0\"/>" >> test-results/results.xml
                  elif [[ "$test_line" =~ ^‚ùå[[:space:]](.+)$ ]]; then
                    test_name="${BASH_REMATCH[1]}"
                    cat >> test-results/results.xml << XML_FAIL
    <testcase name="${test_name}" classname="${folder}" time="0">
      <failure message="Test failed">Test assertion failed</failure>
    </testcase>
XML_FAIL
                  fi
                fi
              done <<< "${folder_tests[$folder]}"
              
              echo "  </testsuite>" >> test-results/results.xml
            done
            
            echo "</testsuites>" >> test-results/results.xml
            
            echo "‚úÖ Generated JUnit XML with ${total_all_tests} tests (${total_all_passed} passed, ${total_all_failed} failed)"
          fi
          
          echo ""
          echo "=========================================="
          echo "TEST SUMMARY"
          echo "=========================================="
          cat /tmp/test-summary.txt
          echo ""
          echo "=========================================="
          echo "DETAILED RESULTS"
          echo "=========================================="
          cat /tmp/test-detail.txt
          echo "üìÑ Full details available in HTML report artifacts"
          echo "=========================================="
          
          # Exit with the original test exit code
          exit $TEST_EXIT_CODE
      
      - name: Show container logs
        if: always()
        run: |
          echo "=== Metasync Container Logs (Last 100 lines) ==="
          docker logs --tail 100 metasync
          echo ""
          echo "=== MongoDB Connection Test ==="
          mongosh --host localhost --port 27017 metasync-test --eval 'db.getCollectionNames()'
          echo ""
          echo "=== MongoDB Collections Content ==="
          mongosh --host localhost --port 27017 metasync-test --eval 'db.clients.countDocuments()'
          mongosh --host localhost --port 27017 metasync-test --eval 'db.models.countDocuments()'
      
      - name: Generate combined HTML report index
        if: always()
        run: |
          cat > test-results/index.html << 'EOF'
          <!DOCTYPE html>
          <html lang="en">
          <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Metasync Test Results</title>
            <style>
              body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                background: #f5f5f5;
              }
              h1 {
                color: #333;
                border-bottom: 3px solid #4CAF50;
                padding-bottom: 10px;
              }
              .test-suite {
                background: white;
                border-radius: 8px;
                padding: 20px;
                margin: 15px 0;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                transition: transform 0.2s;
              }
              .test-suite:hover {
                transform: translateY(-2px);
                box-shadow: 0 4px 8px rgba(0,0,0,0.15);
              }
              .test-suite h2 {
                margin-top: 0;
                color: #2196F3;
              }
              .test-suite a {
                display: inline-block;
                padding: 10px 20px;
                background: #2196F3;
                color: white;
                text-decoration: none;
                border-radius: 4px;
                transition: background 0.3s;
              }
              .test-suite a:hover {
                background: #1976D2;
              }
              .timestamp {
                color: #666;
                font-size: 0.9em;
              }
            </style>
          </head>
          <body>
            <h1>üß™ Metasync API Test Results</h1>
            <p class="timestamp">Generated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')</p>
            <div class="test-suites">
          EOF
          
          # Add links to each test suite report
          for report in test-results/report-*.html; do
            if [ -f "$report" ]; then
              suite_name=$(basename "$report" .html | sed 's/report-//')
              cat >> test-results/index.html << EOF
              <div class="test-suite">
                <h2>üìã ${suite_name}</h2>
                <a href="$(basename "$report")">View Test Report ‚Üí</a>
              </div>
          EOF
            fi
          done
          
          cat >> test-results/index.html << 'EOF'
            </div>
          </body>
          </html>
          EOF
          
          echo "Generated test report index at test-results/index.html"
      
      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            test-results/results-*.xml
          check_name: Test Results
      
      - name: Upload HTML test reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-reports-html
          path: test-results/
          retention-days: 30
      
      - name: Add test report summary
        if: always()
        run: |
          echo "## üìä Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add quick summary
          echo "### üìã Test Suites Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f /tmp/test-summary.txt ]; then
            cat /tmp/test-summary.txt >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add detailed results for each suite
          echo "### üìù Detailed Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Read and parse the test detail file
          if [ -f /tmp/test-detail.txt ]; then
            current_folder=""
            folder_status=""
            in_tests=false
            
            while IFS= read -r line; do
              # Check if this is a folder marker line
              if [[ "$line" =~ ^FOLDER:([^:]+):(PASSED|FAILED)$ ]]; then
                # Close previous folder details if exists
                if [ -n "$current_folder" ]; then
                  echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                  echo "</details>" >> $GITHUB_STEP_SUMMARY
                  echo "" >> $GITHUB_STEP_SUMMARY
                fi
                
                # Extract folder name and status
                current_folder="${BASH_REMATCH[1]}"
                folder_status="${BASH_REMATCH[2]}"
                
                # Start new details section
                echo "<details>" >> $GITHUB_STEP_SUMMARY
                
                if [ "$folder_status" = "PASSED" ]; then
                  echo "<summary>‚úÖ <strong>${current_folder}</strong> - All tests passed</summary>" >> $GITHUB_STEP_SUMMARY
                else
                  echo "<summary>‚ùå <strong>${current_folder}</strong> - Some tests failed</summary>" >> $GITHUB_STEP_SUMMARY
                fi
                
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                in_tests=true
                
              elif [ "$line" = "---" ]; then
                # End of folder section
                in_tests=false
                
              elif [ -n "$line" ] && [ "$in_tests" = true ]; then
                # Individual test result line
                echo "$line" >> $GITHUB_STEP_SUMMARY
              fi
            done < /tmp/test-detail.txt
            
            # Close last folder details if exists
            if [ -n "$current_folder" ]; then
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ö†Ô∏è No test detail file found" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üì• Download Full HTML Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Full detailed reports with assertions and error messages are available in the **test-reports-html** artifact." >> $GITHUB_STEP_SUMMARY
      
      - name: Cleanup
        if: always()
        run: |
          docker stop metasync || true
          docker rm metasync || true

